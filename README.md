# Sentiment Analysis

## Contexte

Ici, un travail exploratoire de NLP(Natural language processing) sur des tweets, le but ainsi est d'explorer les manières de faire du NLP et d'apprendre à récupérer les données twitter qui nous intéresse.

Pour le NLP nous utilisons principalement des bibliothèques classiques:

* Nlpk ( https://www.nltk.org/ )

* Scikit-learn ( https://scikit-learn.org/stable/)

* Keras ( https://keras.io/api/)

* TensorFlow ( https://www.tensorflow.org/)

Enfin pour la récupération de données:

* Tweepy ( https://www.tweepy.org)

Pour recuperer les donnés que j'ai récupérés et les models que j'ai entraînés:
*

De plus, si vous voulez relancer le code ne pas hésiter à utiliser collab ( https:/colab.research.google.com) certains models sont lourd (40 min déchainement sur colab).

## les notebooks

Les notebooks sont organisés de la manière suivante: 

* en premier lieu dataset Ipynb qui explique comment nous formons le dataset pour l'apprentissage de nos modèles.  

* Puis Analyse_de_sentiment.Ipynb où nous faisons une première approche sur l'analyse de sentiment.  

* reduction.Ipynb nous approfondissons le précédent grace à la réduction de dimension.  

* Enfin recuperation_tweet.Ipynb dans lequel nous abordons la récupération des données twitter. 
